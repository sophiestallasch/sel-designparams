[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Database and Online Supplemental Material",
    "section": "",
    "text": "Database of Design Parameters\nOSM A: Materials and Methods\nOSM B: Application"
  },
  {
    "objectID": "osm_b/index.html",
    "href": "osm_b/index.html",
    "title": "OSM B: Application",
    "section": "",
    "text": "This demo presents two scenarios illustrating how our design parameters are applied in power analyses when planning randomized intervention studies on students’ SEL outcomes. We demonstrate how to determine"
  },
  {
    "objectID": "osm_b/index.html#prerequisites",
    "href": "osm_b/index.html#prerequisites",
    "title": "OSM B: Application",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nR Setup\nWe showcase power analysis in R using the package PowerUpR (Bulus et al., 2021). It implements the power formulas given in Dong and Maynard (2013). Specifically, we use the functions mrss.ira() to calculate the MRSS in Scenario 1 and mdes.cra3() to calculate the MDES in Scenario 2 for the main treatment effect. Researchers may also use the companion PowerUpR shiny app (Ataneka et al., 2023) or the Excel tool PowerUp! (Dong et al., 2015). Note that there are several other appropriate software solutions for planning IRTs and CRTs, such as Optimal Design (Spybrook et al., 2011).\n\n# -- Load packages\n\n# Data handling\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\n\n# Table processing and plotting\nlibrary(knitr)\nlibrary(ggplot2)\n\n# Power analysis \nlibrary(PowerUpR)\n\n\n\nAssumptions\nFor each scenario, we assume a balanced design where students (Scenario 1) or schools (Scenario 2) are randomly assigned to experimental conditions in equal shares (i.e., 50% of the sample in the treatment group and 50% in the control group). Further, we set the desired power at 80% (1-β = 0.80) and use a two-tailed test with Type I error rate of 5% (α = 0.05) which allows testing of potentially unexpected negative effects of the intervention on the outcome. Note that these assumptions correspond to the default settings in PowerUpR."
  },
  {
    "objectID": "osm_b/index.html#scenario-1-irt",
    "href": "osm_b/index.html#scenario-1-irt",
    "title": "OSM B: Application",
    "section": "Scenario 1: IRT",
    "text": "Scenario 1: IRT\n\nA lab-based IRT on outcomes across multiple contexts and domains in elementary school\n\nA research team has developed an universal intervention to promote elementary students’ SEL outcomes across multiple contexts and domains. The team plans a single-level lab-based randomized experiment to test whether the new approach is effective under controlled lab conditions across different assessment methods.\nThe researchers expect a treatment effect of a size typically reported for previous randomized experiments on SEL outcomes. The meta-analysis by Wilson et al. (2025, Table 2) suggests that the average standardized mean differences (SMD) across social and behavioral outcomes lie in the range 0.07 ≤ SMD ≤ 0.35, with a median of Mdn(SMD) = 0.22. The research team therefore considers a treatment effect of this size on students’ SEL outcomes plausible and meaningful. The researchers thus conduct power analyses to determine the required number of students that should be sampled to ensure their IRT can detect a minimum detectable effect size of MDES = 0.22 (with 1-β = 0.80 and α = 0.05 in a two-tailed test).\n\n# set the MDES\nes_1l &lt;- .22\n\n\nBaseline Design without Covariates\nIn a first setup, the research team considers a design without covariates.\n\n# apply PowerUpR::mrss.ira()\nmrss.ira(\n  es=es_1l,          # MDES\n  power=.80,         # Power; default: 80%\n  alpha=.05,         # Probability of Type I error; default: 5% \n  two.tailed=TRUE,   # Hypothesis test; default: two-tailed\n  p=.50,             # Proportion of students in the treatment group; default: 50%\n  n0=10,             # Starting value for finding the sample size; default: 10\n  tol=.10,           # Tolerance of iterations for finding the sample size; default: 0.1\n  g1=0,              # Number of covariates; default: 0\n  r21=0              # Proportion of explained variance by covariates; default: 0\n  )\n\nn = 651 \n\n\nThe MRSS equals 651. Therefore, in total, N = 651 students are required to achieve MDES = 0.22 when omitting covariates. Hence, the researchers would have to randomly assign n = 326 students to the treatment group and n = 326 students to the control group.\n\n\nDesigns with Covariates\nIn a second setup, the research team would like to test the impact of different covariate sets (in terms of R2Total) on the required sample size. Because the intervention targets SEL outcomes across multiple domains and contexts (as opposed to a specific measure), the researchers rely on the meta-analytic summaries of the design parameters. Specifically, they consult the results of MA-1 with student self-reports, parent reports, and teacher reports in elementary school. (Note that design parameters are not available for teacher reports in Model Set 2-BL and Model Set 3-SD+BL.)\nMoreover, the team intends to take into account the statistical uncertainty associated with the estimated design parameters. For this purpose, the researchers determine conservative upper/liberal lower bounds for the MRSS by drawing on the respective lower/upper bound estimates of the 95% CIs of the meta-analytic averages of R2Total.\n\n# load meta-analytic summaries\nload(url(\"https://raw.githubusercontent.com/sophiestallasch/sel-designparams/main/data/dp_ma.pub.rda\"))\n\nIf you encounter any issues, click here to download the .rda file and load it manually into R.\n\ndp_1l &lt;- dp_ma %&gt;% \n  # select relevant design parameters\n  filter(Type == \"MA-1\", \n         Population == \"Total\",\n         Design == \"1L-D\",\n         Edu.level == \"Elementary\") %&gt;% \n  \n  # select relevant columnns\n  select(Method, Set, n_Covariates, Parameter, Average, starts_with(\"CI\"))\n\nTable 1 shows all design parameters applied in the power analyses.\n\n\nCode\n# inspect selected design parameters\nkable(dp_1l %&gt;% \n        mutate(across(c(Average:CI.ub), ~sprintf(\"%.2f\", .))))\n\n\n\n\nTable 1: Design Parameters for Scenario 1\n\n\n\n\n\n\nMethod\nSet\nn_Covariates\nParameter\nAverage\nCI.lb\nCI.ub\n\n\n\n\nStudent\n2-BL\n1\nR2_Total\n0.15\n0.14\n0.16\n\n\nStudent\n3-SD+BL\n6\nR2_Total\n0.16\n0.15\n0.17\n\n\nStudent\n1-SD\n5\nR2_Total\n0.04\n0.03\n0.05\n\n\nParent\n2-BL\n1\nR2_Total\n0.46\n0.45\n0.47\n\n\nParent\n3-SD+BL\n6\nR2_Total\n0.46\n0.46\n0.47\n\n\nParent\n1-SD\n5\nR2_Total\n0.05\n0.00\n0.10\n\n\nTeacher\n1-SD\n5\nR2_Total\n0.06\n0.04\n0.08\n\n\n\n\n\n\n\n\nUsing these estimates, the research team systematically studies how the various covariate sets influence the MRSS.\n\n# prepare database\ndp_1l &lt;- dp_1l %&gt;% \n  pivot_longer(c(Average:CI.ub), \n               names_to = \"statistic\", values_to = \"r2_total\")\n\n\n# custom function to vectorize PowerUpR::mrss.ira() across varying model sets\nvectorize_mrss.ira &lt;- function(g1, r21, ...) {\n  parms &lt;- list(es = es_1l, g1 = g1, r21 = r21)\n  d_out &lt;- exec(getFromNamespace(\"mrss.ira\", ns = \"PowerUpR\"), !!!parms)\n  d_out$n\n}\n\n# apply vectorize_mrss.ira()\nd_1l &lt;- dp_1l %&gt;% \n  mutate(mrss = map2_dbl(n_Covariates, r2_total, vectorize_mrss.ira))\n\n\n# clean and reshape results \nd_1l &lt;- d_1l %&gt;% \n  select(Method, Set, statistic, mrss) %&gt;% \n  mutate(statistic = case_match(statistic,\n                                \"Average\" ~ \"MRSS\",\n                                \"CI.lb\"   ~ \"MRSS conservative\",\n                                \"CI.ub\"   ~ \"MRSS liberal\")) %&gt;%\n  pivot_wider(names_from = statistic, values_from = mrss) %&gt;% \n  arrange(Method, Set)\n\nTable 2 lists the results; Figure 1 visualizes them.\n\n\n\n\nCode\n# show results\nkable(d_1l)\n\n\n\n\nTable 2: MRSS for Different Covariate Sets by Assessment Method\n\n\n\n\n\n\nMethod\nSet\nMRSS\nMRSS conservative\nMRSS liberal\n\n\n\n\nStudent\n1-SD\n624\n633\n615\n\n\nStudent\n2-BL\n553\n562\n545\n\n\nStudent\n3-SD+BL\n548\n556\n539\n\n\nParent\n1-SD\n621\n651\n588\n\n\nParent\n2-BL\n352\n358\n347\n\n\nParent\n3-SD+BL\n349\n354\n344\n\n\nTeacher\n1-SD\n614\n627\n601\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(d_1l, aes(x = Set, y = MRSS, fill = Method)) +\n  geom_hline(yintercept = d_1l.0$n, linetype = \"dashed\") + \n  geom_col(position = position_dodge(width = 0.8, preserve = \"single\"), width = 0.7) +\n  geom_errorbar(\n    aes(ymin = `MRSS conservative`, ymax = `MRSS liberal`),\n    position = position_dodge(width = 0.8, preserve = \"single\"), \n    width = 0.2\n    ) +\n  scale_y_continuous(breaks = c(seq(0, 600, 200), d_1l.0$n), limits = c(NA, 700)) + \n  scale_fill_grey(start = 0.3, end = 0.8) +\n  labs(y = \"MRSS\") +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank(), \n    axis.title.x = element_blank(),\n    legend.title = element_blank()\n  ) +\n  annotate(\n    \"text\", x = Inf, y = d_1l.0$n, label = \"Baseline\",\n    size = 3.5, hjust = 1, vjust = -0.5\n  )\n\n\n\n\n\nFigure 1: MRSS (with conservative/liberal bounds) for Different Covariate Sets by Assessment Method\n\n\n\n\n\n\n\n\n\n\nFigure 1 shows that adding covariates can substantially reduce the MRSS. As detailed in Table 2, entering the point estimates of R2Total into the power formula results in total sample size requirements of 614 ≤ N ≤ 624 when controlling for Set 1-SD, 352 ≤ N ≤ 553 when controlling for Set 2-BL, and 349 ≤ N ≤ 548 when controlling for Set 3-SD+BL, depending on the assessment method. Using the lower bound estimates of the 95% CI of R2Total, and thus, following a conservative approach, the MRSS varies between N = 354 (Parent, 3-SD+BL) and N = 651 (Parent, 1-SD). In contrast, using the respective upper bound estimates to adopt a rather optimistic liberal approach, the MRSS varies between N = 344 (Parent, 3-SD+BL) and N = 615 (Student, 1-SD).\nTo conclude, if covariates cannot be included, a total of N = 651 elementary students are necessary to achieve MDES = 0.22. However, when covariates are included in the design, the required sample size depends on the team’s risk preferences. For example, if they opted for a conservative approach by assessing both sociodemographic characteristics and a pretest, the researchers should recruit at least N = 556/354 students to adequately power their IRT to detect SMD = 0.22 based on student self-reports/parent ratings."
  },
  {
    "objectID": "osm_b/index.html#scenario-2-crt",
    "href": "osm_b/index.html#scenario-2-crt",
    "title": "OSM B: Application",
    "section": "Scenario 2: CRT",
    "text": "Scenario 2: CRT\n\nA field three-level CRT on enjoyment of learning among Grade 4 students\n\nThe research team found that their intervention improved 4th graders’ self-reported enjoyment of learning with SMD = 0.22. The team plans a large-scale trial to evaluate whether the intervention is also effective when implemented by teachers in regular classroom settings. To avoid unintentionally exposing the control group to the intervention, the researchers want to carry out a three-level cluster-randomized trial, where whole schools will be randomized to experimental conditions. 80 schools will participate in the study. From each of these schools, the team intends to sample 2 classrooms, with 20 students per classroom. Given this sample size, the researchers want to determine whether their CRT achieves MDES = 0.22 (with 1-β = .80 and α = .05 in a two-tailed test). Since the intervention targets a specific measure, the team enters the point estimates for the design parameters into their power calculations.\nAgain, the researchers allow for the statistical uncertainty associated with the estimated design parameters. They determine conservative upper/liberal lower bound estimates for the MDES by drawing on the respective upper/lower bounds of the 95% CIs of the ICCs and the respective lower/upper bounds of the 95% CIs of the R2 values.\n\n# set the sample size\nn_3l = 20           # Number of students per classroom\nJ_3l = 2            # Number of classrooms per school\nK_3l = 80           # Number of schools\n\n\n# load point estimates\nload(url(\"https://raw.githubusercontent.com/sophiestallasch/sel-designparams/main/data/dp_pe.pub.rda\"))\n\nIf you encounter any issues, click here to download the .rda file and load it manually into R.\n\ndp_3l &lt;- dp_pe %&gt;% \n  # select relevant design parameters\n  filter(Population == \"Total\",\n         Design == \"3L-D\",\n         Edu.level == \"Elementary\",\n         Grade == 4,\n         Method == \"Student\",\n         Measure == \"Enjoyment of learning\") %&gt;% \n  \n  # calculate 95% CIs \n  mutate(CI.lb = Estimate - 1.96*SE,\n         CI.ub = Estimate + 1.96*SE) %&gt;% \n  \n  # truncate to [0,1], if necessary\n  mutate(across(starts_with(\"CI\"), ~ pmax(0, pmin(1, .)))) %&gt;% \n  \n  # select relevant columns\n  select(Set, n_Covariates, Parameter, Estimate, starts_with(\"CI\"))\n\nTable 3 shows all design parameters applied in the power analyses.\n\n\nCode\n# inspect selected design parameters\nkable(dp_3l %&gt;% \n        mutate(across(c(Estimate, starts_with(\"CI\")), ~sprintf(\"%.2f\", .))))\n\n\n\n\nTable 3: Design Parameters for Scenario 2\n\n\n\n\n\n\nSet\nn_Covariates\nParameter\nEstimate\nCI.lb\nCI.ub\n\n\n\n\n0\n0\nICC_Classroom\n0.08\n0.03\n0.12\n\n\n0\n0\nICC_School\n0.05\n0.02\n0.08\n\n\n1-SD\n5\nR2_Student\n0.06\n0.05\n0.07\n\n\n1-SD\n5\nR2_Classroom\n0.02\n0.00\n0.04\n\n\n1-SD\n5\nR2_School\n0.14\n0.06\n0.22\n\n\n2-BL\n1\nR2_Student\n0.21\n0.19\n0.23\n\n\n2-BL\n1\nR2_Classroom\n0.27\n0.21\n0.34\n\n\n2-BL\n1\nR2_School\n0.48\n0.36\n0.59\n\n\n3-SD+BL\n6\nR2_Student\n0.23\n0.21\n0.25\n\n\n3-SD+BL\n6\nR2_Classroom\n0.28\n0.21\n0.35\n\n\n3-SD+BL\n6\nR2_School\n0.50\n0.39\n0.61\n\n\n\n\n\n\n\n\n\nBaseline Design without Covariates\nAgain, in a first setup, the research team considers a design without covariates.\n\n# point estimates\nmdes.cra3(\n  power=.80,         # Power; default: 80%\n  alpha=.05,         # Probability of Type I error; default: 5% \n  two.tailed=TRUE,   # Hypothesis test; default: two-tailed\n  p=.50,             # Proportion of students in the treatment group; default: 50%\n  rho2 = .08,        # Between-classroom differences (ICC_Classroom)\n  rho3 = .05,        # Between-school differences (ICC_School)\n  g3=0,              # Number of covariates; default: 0\n  r21=0,             # Proportion of explained variance by covariates at the student level (R2_Student); default: 0\n  r22=0,             # Proportion of explained variance by covariates at the classroom level (R2_Classroom); default: 0\n  r23=0,             # Proportion of explained variance by covariates at the school level (R2_School); default: 0\n  n = n_3l,          # Number of students per classroom\n  J = J_3l,          # Number of classrooms per school\n  K = K_3l           # Number of schools\n  )\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.212 95% CI [0.063,0.361]\n---------------------------------------\nDegrees of freedom: 78\nStandardized standard error: 0.075\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n# ICCs: upper bound of the 95% CIs = conservative\nmdes.cra3(rho2 = .12, rho3 = .08, n = n_3l, J = J_3l, K = K_3l)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.254 95% CI [0.076,0.432]\n---------------------------------------\nDegrees of freedom: 78\nStandardized standard error: 0.089\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n# ICCs: lower bound of the 95% CIs = liberal\nmdes.cra3(rho2 = .03, rho3 = .02, n = n_3l, J = J_3l, K = K_3l)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.154 95% CI [0.046,0.262]\n---------------------------------------\nDegrees of freedom: 78\nStandardized standard error: 0.054\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\nWhen not using covariates, the MDES equals 0.21 with the point estimates, 0.25 with the upper bound estimates of the 95% CIs, and 0.15 with the lower bound estimates of the 95% CIs of the ICCs. Consequently, K = 80 schools would suffice to achieve an MDES of 0.22—provided the researchers adopt a liberal (but potentially risky) approach to power analysis. To ensure the robustness of the design, they proceed to systematically examine how different covariate sets influence the MDES.\n\n# prepare database\ndp_3l &lt;- dp_3l %&gt;% \n  pivot_longer(c(Estimate:CI.ub), \n               names_to = \"statistic\", values_to = \"r2\") %&gt;%\n  pivot_wider(names_from = Parameter, values_from = r2) %&gt;% \n\n# ICC: upper bound of the 95% CI + R2: lower bound of the 95% CI = conservative\n# ICC: lower bound of the 95% CI + R2: upper bound of the 95% CI = liberal\n  mutate(approach = case_when(\n    statistic == \"Estimate\" ~ \"MDES\",\n    Set == \"0\" & statistic == \"CI.lb\" ~ \"MDES liberal\",\n    Set == \"0\" & statistic == \"CI.ub\" ~ \"MDES conservative\",\n    Set != \"0\" & statistic == \"CI.lb\" ~ \"MDES conservative\",\n    Set != \"0\" & statistic == \"CI.ub\" ~ \"MDES liberal\"))\n\n# extract ICCs\nicc &lt;- dp_3l %&gt;% \n  filter(Set == \"0\") %&gt;% \n  select(approach, starts_with(\"ICC\"))\n\ndp_3l &lt;- dp_3l %&gt;% \n  # fill in ICCs for covariate model sets\n  left_join(icc, by = \"approach\", suffix = c(\"_\", \"\")) %&gt;% \n  select(Set, n_Covariates, approach, starts_with(\"ICC\"), starts_with(\"R2\"), -ends_with(\"_\")) %&gt;% \n  # remove Model Set 0\n  filter(Set != \"0\")\n\n\n# custom function to vectorize PowerUpR::mdes.cra3() across varying model sets\nvectorize_mdes.cra3 &lt;- function(rho2, rho3, g3, r21, r22, r23, ...) {\n  parms &lt;- list(\n    rho2 = rho2, rho3 = rho3,           \n    g3 = g3, \n    r21 = r21, r22 = r22, r23 = r23,\n    n = n_3l, J = J_3l, K = K_3l\n  )\n  d_out &lt;- exec(getFromNamespace(\"mdes.cra3\", ns = \"PowerUpR\"), !!!parms)\n  d_out$mdes[1]\n}\n\n# apply vectorize_mdes.cra3()\nd_3l &lt;- dp_3l %&gt;% \n  mutate(mdes = pmap_dbl(\n    list(\n      ICC_Classroom, ICC_School, n_Covariates, R2_Student, R2_Classroom, R2_School\n      ), \n    vectorize_mdes.cra3))\n\n\n# clean and reshape results\nd_3l &lt;- d_3l %&gt;% \n  select(-starts_with(c(\"ICC\", \"R2\"))) %&gt;% \n  pivot_wider(names_from = approach, values_from = mdes)\n\nTable 4 lists the results; Figure 2 visualizes them.\n\n\n\n\nCode\n# show results\nkable(d_3l %&gt;% \n        mutate(across(contains(\"MDES\"), ~sprintf(\"%.2f\", .))))\n\n\n\n\nTable 4: MDES for Different Covariate Sets\n\n\n\n\n\n\nSet\nn_Covariates\nMDES\nMDES conservative\nMDES liberal\n\n\n\n\n1-SD\n5\n0.20\n0.25\n0.14\n\n\n2-BL\n1\n0.17\n0.22\n0.12\n\n\n3-SD+BL\n6\n0.17\n0.21\n0.12\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(d_3l, aes(x = Set, y = `MDES`)) +\n  geom_hline(yintercept = es_1l, linetype = \"dashed\") + \n  geom_segment(aes(xend = Set, y = 0, yend = `MDES`), color = \"grey70\", linewidth = 1.5) +\n  geom_point(aes(y = `MDES`), size = 4, color = \"black\", fill = \"darkgrey\", shape = 21) +\n  geom_errorbar(\n    aes(ymin = `MDES conservative`, ymax = `MDES liberal`),\n    width = 0.2\n  ) +\n  labs(y = \"MDES\") +\n  theme_minimal(base_size = 13) +\n  theme(\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank(),\n        axis.title.x = element_blank(),\n    legend.title = element_blank()\n  )  +\n  annotate(\n    \"text\", x = Inf, y = es_1l, label = \"Target\",\n    size = 3.5, hjust = 1, vjust = -0.5\n  )\n\n\n\n\n\nFigure 2: MDES (with conservative/liberal bounds) for Different Covariate Sets\n\n\n\n\n\n\n\n\n\n\nFigure 2 illustrates that covariates can indeed lower the MDES. Table 4 shows that by applying the point estimates, 0.17 ≤ MDES ≤ 0.20, depending on the covariate set. Entering the upper bound estimates of the 95% CIs of the ICCs plus the lower bound estimates of the 95% CIs of the R2s under a conservative approach, the MDES varies between MDES = 0.21 and MDES = 0.25. In contrast, using the respective the lower bound estimates of the 95% CIs of the ICCs in combination with the upper bound estimates of the 95% CIs of R2s under a liberal approach, the MDES varies between MDES = 0.12 and MDES = 0.14.\nIn summary, with a fixed maximum of K = 80 schools in total, the research team should at least consider adding a baseline measure, hence, to pretest students’ enjoyment of learning, given statistical uncertainty. If doing so, the researchers can be confident that the sample size of their CRT will be large enough to detect SMD = 0.22 based on student self-reports."
  },
  {
    "objectID": "dp/index.html",
    "href": "dp/index.html",
    "title": "Database of Design Parameters",
    "section": "",
    "text": "To support power analyses for single-level and multilevel randomized intervention studies on SEL outcomes, we have generated a comprehensive database that includes (a) point estimates and (b) meta-analytic summaries of design parameters. As discussed in the Data Note, we recommend aligning the design parameters with the key characteristics of the target intervention. This involves considering:\nImportantly, if the target measure or other characteristics of the planned study (e.g., the target grade) do not align well with the characteristics of the samples used to estimate the current design parameters, or if the available point estimates have large standard errors, we recommend utilizing the meta-analytic summaries of the design parameters that most closely reflect the target intervention.\nTo select the design parameters or their meta-analytic summaries from the tables below, researchers can use the interactive filter functions or adapt the R code provided in OSM B."
  },
  {
    "objectID": "dp/index.html#point-estimates",
    "href": "dp/index.html#point-estimates",
    "title": "Database of Design Parameters",
    "section": "Point Estimates",
    "text": "Point Estimates"
  },
  {
    "objectID": "dp/index.html#meta-analytic-summaries",
    "href": "dp/index.html#meta-analytic-summaries",
    "title": "Database of Design Parameters",
    "section": "Meta-Analytic Summaries",
    "text": "Meta-Analytic Summaries\n\n\n\n\n\n\n\n\nTable Notes\n\n\n\nShow notes\n\n\n\n\nKey characteristics\n\n\n\n\nPopulation\nPopulation\nTotal = Total student population (overall; all school types)\n\n\nAcademic = Academic track student population (\"Gymnasium\")\n\n\nNon-academic = Non-academic track student population (other school types)\n\n\nDesign\nExperimental design\n1L-D = Single-level design (individual students independently sampled)\n\n\n2L-D = Two-level design (students within schools)\n\n\n3L-D = Three-level design (students within classrooms within schools)\n\n\nEdu.level\nEducation level\nElementary = Elementary education (grades 1–4)\n\n\nLower secondary = Lower secondary education (grades 5–10)\n\n\nUpper secondary = Upper secondary education (grades 11–13)\n\n\nMethod\nAssessment method\nStudent = Student self-report\n\n\nParent = Parent rating\n\n\nTeacher = Teacher rating\n\n\nDomain\nSEL domain\nSelf = Self-orientation\n\n\nOther = Other-orientation\n\n\nTask = Task-orientation\n\n\nContext\nSEL context\nMathematics/Science/ICT/Verbal: German/English = School-related: subject-specific\n\n\nSchool = School-related: whole-school academic\n\n\nGeneral = General, context-independent\n\n\nMeasure\nOutcome measure\nSeveral, depends on the context\n\n\nGrade\nGrade\nGrades 1 to 13\n\n\nType\nType of meta-analysis\nMA-1 = Across domains and contexts\n\n\nMA-2 = Within domains, across contexts\n\n\nMA-3 = Within domains and contexts\n\n\nSet\nModel set\n0 = No covariate adjustment (\"empty\")\n\n\n1-SD = Adjusted for sociodemographic characteristics\n\n\n2-BL = Adjusted for baseline measure of the outcome\n\n\n3-SD+BL = Adjusted for both\n\n\nKey statistics\n\n\nParameter\nDesign parameter\nicc_l2 = Intraclass correlation at classroom level (ρClassroom)\n\n\nicc_l3 = Intraclass correlation at school level (ρSchool)\n\n\nr2_l1 = Explained variance at student level (R²Student)\n\n\nr2_l2 = Explained variance at classroom level (R²Classroom)\n\n\nr2_l3 = Explained variance at school level (R²School)\n\n\nr2_t = Total explained variance across all students (R²Total; 1L-D only)\n\n\nEstimate\nPoint estimate\n\n\n\nAverage\nMeta-analytic average\n\n\n\nSE\nStandard error\n\n\n\nFurther information\n\n\nSample\nProbability sample\nDESI = Assessment of Student Achievements in German and English as a Foreign Language\n\n\nIQB Trends = IQB Trends in Student Achievement 2016\n\n\nPISA 2003 = Programme for International Student Assessment, 2003 cycle\n\n\nPISA 2006 = Programme for International Student Assessment, 2006 cycle\n\n\nPISA 2009 = Programme for International Student Assessment, 2009 cycle\n\n\nPISA 2012 = Programme for International Student Assessment, 2012 cycle\n\n\nNEPS-SC2 = National Educational Panel Study, starting cohort 2—kindergarten\n\n\nNEPS-SC3 = National Educational Panel Study, starting cohort 3—grade 5\n\n\nNEPS-SC4 = National Educational Panel Study, starting cohort 4—grade 9\n\n\nWave\nAssessment wave\n\n\n\nLag\nTime lag (months)\n\n\n\nVariable\nOutcome variable\n\n\n\nReliability\nOutcome reliability\n\n\n\nn_Students\nNumber of students\n\n\n\nn_Classrooms\nNumber of classrooms\n\n\n\nn_Schools\nNumber of schools\n\n\n\nn_Covariates\nNumber of covariates\n\n\n\nk\nObserved design parameters\n\n\n\nJ\nNumber of samples\n\n\n\nFit.method\nFitting method\nFE = Fixed-effect model\n\n\nREML = Random-effects model\n\n\nCI.lb\n95% Confidence interval: lower bound\n\n\n\nCI.ub\n95% Confidence interval: upper bound\n\n\n\nPI.lb\nPrediction interval: lower bound\n(REML only)\n\n\nPI.ub\nPrediction interval: upper bound\n(REML only)\n\n\nTau2_Within\nWithin-sample heterogeneity\n(τ²Within; REML only)\n\n\nTau2_Between\nBetween-sample heterogeneity\n(τ²Between; REML only)\n\n\nI2_Total\nI² statistics: total\n(I²Total; REML only)\n\n\nI2_Within\nI² statistics: within samples\n(I²Within; REML only)\n\n\nI2_Between\nI² statistics: between samples\n(I²Between; REML only)"
  },
  {
    "objectID": "osm_a/index.html",
    "href": "osm_a/index.html",
    "title": "OSM A: Materials and Methods",
    "section": "",
    "text": "Download"
  }
]